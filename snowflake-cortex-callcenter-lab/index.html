
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Snowflake Cortex AI for Call Center Transcript Analysis</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/claat-public/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14" ga4id=""></google-codelab-analytics>
  <google-codelab codelab-gaid="UA-XXXXXXXXX-X"
                  codelab-ga4id=""
                  id="snowflake-cortex-callcenter-lab"
                  title="Snowflake Cortex AI for Call Center Transcript Analysis"
                  environment="web"
                  feedback-link="https://github.com/datalab-solutions/snowflake-codelabs/issues">
    
      <google-codelab-step label="Overview" duration="1">
        <p><a href="https://github.com/datalabsolutions/AI-Labs/raw/main/snowflake-cortex-callcenter-lab/assets/audio-files.zip" target="_blank">Download Demo Files (ZIP)</a></p>
<p>This hands-on lab introduces participants to Snowflake Cortex AI&#39;s ability to extract valuable insights from unstructured documents using large language models. The lab uses examples of call center transcripts stored as PDFs. Participants will explore functions such as <a href="https://docs.snowflake.com/en/sql-reference/functions/parse_document" target="_blank"><code>PARSE_DOCUMENT</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/complete" target="_blank"><code>COMPLETE</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/translate" target="_blank"><code>TRANSLATE</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/sentiment" target="_blank"><code>SENTIMENT</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/entity_sentiment" target="_blank"><code>ENTITY_SENTIMENT</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/summarize" target="_blank"><code>SUMMARIZE</code></a>, and <a href="https://docs.snowflake.com/en/sql-reference/functions/extract_answer" target="_blank"><code>EXTRACT_ANSWER</code></a>. These tools empower users to parse, translate, analyze, and query unstructured customer support data to uncover sentiment, highlight issues, and summarize conversations at scale.</p>
<p>Whether you&#39;re a data engineer, business analyst, or AI enthusiast, this lab will help you understand how to turn raw documents into structured, actionable data using generative AI.</p>
<h2 class="checklist" is-upgraded>What you&#39;ll learn</h2>
<ul class="checklist">
<li>Upload and manage unstructured documents in Snowflake.</li>
<li>Extract and transform transcript text with <a href="https://docs.snowflake.com/en/sql-reference/functions/parse_document-snowflake-cortex" target="_blank"><code>PARSE_DOCUMENT</code></a>.</li>
<li>Structure data using prompt engineering and the <a href="https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex" target="_blank"><code>COMPLETE</code></a> function.</li>
<li>Translate text with <a href="https://docs.snowflake.com/en/sql-reference/functions/translate-snowflake-cortex" target="_blank"><code>TRANSLATE</code></a>.</li>
<li>Analyze sentiment using <a href="https://docs.snowflake.com/en/sql-reference/functions/sentiment-snowflake-cortex" target="_blank"><code>SENTIMENT</code></a> and <a href="https://docs.snowflake.com/en/sql-reference/functions/entity_sentiment-snowflake-cortex" target="_blank"><code>ENTITY_SENTIMENT</code></a>.</li>
<li>Summarize content with <a href="https://docs.snowflake.com/en/sql-reference/functions/summarize-snowflake-cortex" target="_blank"><code>SUMMARIZE</code></a>.</li>
<li>Extract answers using <a href="https://docs.snowflake.com/en/sql-reference/functions/extract_answer-snowflake-cortex" target="_blank"><code>EXTRACT_ANSWER</code></a>.</li>
</ul>
<h2 is-upgraded>Prerequisites</h2>
<ul>
<li>A <a href="https://trial.snowflake.com/?owner=SPN-PID-452710" target="_blank">Snowflake account</a> in a cloud region where <strong>Snowflake Cortex LLM functions</strong> are supported.</li>
<li>Basic familiarity with SQL and the Snowflake UI.</li>
<li>Access all the scripts for this Lab <a href="https://github.com/datalabsolutions/AI-Labs/tree/main/snowflake-cortex-callcenter-lab" target="_blank">on Github</a></li>
</ul>
<p>ðŸ’¡ <strong>Tip:</strong> Not all Snowflake regions currently support Cortex LLM functions. Use the <a href="https://docs.snowflake.com/en/user-guide/snowflake-cortex-overview#llm-function-availability" target="_blank">LLM Function Availability</a> page to check which cloud regions are supported before creating your account.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Environment Configuration" duration="5">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Create the core Snowflake resources needed to run the AI Lab. This includes a database, warehouse, schemas, and a stage for uploading PDFs.</p>
<h2 is-upgraded>Download Script</h2>
<p>Download the source code for this step <a href="https://github.com/datalabsolutions/AI-Labs/blob/main/snowflake-cortex-callcenter-lab/scripts/01-AI-LAB-CONFIGURATION.sql" target="_blank">here</a>.</p>
<h2 is-upgraded>Description</h2>
<p>This setup script prepares your Snowflake environment to ingest and process unstructured call center transcripts.</p>
<ul>
<li><code>CREATE DATABASE</code> ensures your lab operates in a clean and isolated environment.</li>
<li><code>CREATE WAREHOUSE</code> provisions compute resources for running your queries. It&#39;s configured to minimize cost with automatic suspend/resume settings.</li>
<li><code>CREATE SCHEMA</code> creates logical namespaces for raw files (<code>RAW</code>) and processed/intermediate data (<code>STAGE</code>).</li>
<li><code>CREATE STAGE</code> sets up a secure location to upload PDF documents. It supports directory table creation and uses Snowflake-managed encryption.</li>
</ul>
<h2 is-upgraded>Set Snowflake Context</h2>
<p>Before executing any commands, set your session to the appropriate context:</p>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA RAW;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create the Database</h2>
<pre><code language="language-sql" class="language-sql">CREATE DATABASE IF NOT EXISTS LLM_CORTEX_DEMO_DB;
</code></pre>
<h2 is-upgraded>Step 2: Create a Compute Warehouse</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE WAREHOUSE USER_STD_XSMALL_WH
WITH
    WAREHOUSE_SIZE = &#39;XSMALL&#39;
    WAREHOUSE_TYPE = &#39;STANDARD&#39;
    AUTO_SUSPEND = 60
    AUTO_RESUME = TRUE
    INITIALLY_SUSPENDED = TRUE;
</code></pre>
<h2 is-upgraded>Step 3: Create Required Schemas</h2>
<pre><code language="language-sql" class="language-sql">CREATE SCHEMA IF NOT EXISTS LLM_CORTEX_DEMO_DB.RAW;
CREATE SCHEMA IF NOT EXISTS LLM_CORTEX_DEMO_DB.STAGE;
</code></pre>
<h2 is-upgraded>Step 4: Create an Internal Stage for PDF Uploads</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE STAGE LLM_CORTEX_DEMO_DB.RAW.INT_STAGE_DOC_RAW
    DIRECTORY = ( ENABLE = true )
    ENCRYPTION = ( TYPE = &#39;SNOWFLAKE_SSE&#39; );
</code></pre>
<h2 is-upgraded>Upload PDF Files to the Internal Stage</h2>
<p>Your internal stage <code>LLM_CORTEX_DEMO_DB.RAW.INT_STAGE_DOC_RAW</code> is already set up.</p>
<h3 is-upgraded>Using Snowsight:</h3>
<ol type="1">
<li>In Snowsight, go to <strong>Databases</strong>.</li>
<li>Click on <code>LLM_CORTEX_DEMO_DB</code> &gt; <code>RAW</code> &gt; <code>Stages</code>.</li>
<li>Select <code>INT_STAGE_DOC_RAW</code>.</li>
<li>Click the <strong>+ Files</strong> tab.</li>
<li>Click <strong>Upload</strong> and add one or more call center transcript PDFs.</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="PARSE_DOCUMENT" duration="7">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>PARSE_DOCUMENT()</code> function to extract the contents of uploaded PDF files from your internal stage and store them in a structured format.</p>
<h2 is-upgraded>Download Script</h2>
<p>Download the source code for this step <a href="https://github.com/datalabsolutions/AI-Labs/blob/main/snowflake-cortex-callcenter-lab/scripts/02-AI-LAB-PARSE_DOCUMENT.sql" target="_blank">here</a>.</p>
<h2 is-upgraded>Instructions</h2>
<p>You will now query the internal stage and use Snowflake Cortex to extract and parse the call center transcripts.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<p>Ensure you&#39;re working in the correct context before running the extraction steps:</p>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table for Parsed Results</h2>
<p>This table will store the extracted content for each uploaded file:</p>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT (
    FILE_NAME STRING,
    TRANSCRIPT VARCHAR
);
</code></pre>
<h2 is-upgraded>Step 2: Extract PDF Content from Stage</h2>
<p>The query below uses <code>PARSE_DOCUMENT()</code> to extract and convert each PDF to readable layout format:</p>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT
SELECT 
    FILE_NAME,
    TO_VARCHAR(
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
            @LLM_CORTEX_DEMO_DB.RAW.INT_STAGE_DOC_RAW,
            FILE_PATH,
            { &#39;mode&#39;: &#39;LAYOUT&#39; }
        ):content::string
    ) AS TRANSCRIPT
FROM
(
    SELECT DISTINCT
        METADATA$FILENAME AS FILE_PATH,
        SPLIT_PART(METADATA$FILENAME, &#39;/&#39;, -1) AS FILE_NAME
    FROM @LLM_CORTEX_DEMO_DB.RAW.INT_STAGE_DOC_RAW/
) AS A;
</code></pre>
<p>ðŸ’¡ <strong>Note:</strong> This approach stores both the filename and parsed content for downstream use.</p>
<h2 is-upgraded>Step 3: View Parsed Results</h2>
<p>Run the following query to view the extracted content from your PDF files:</p>
<pre><code language="language-sql" class="language-sql">SELECT FILE_NAME, TRANSCRIPT
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="EXTRACT_ANSWER" duration="7">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>EXTRACT_ANSWER()</code> function to identify specific details in a transcript, such as the caller&#39;s name, call date, and duration, and store them in a structured table.</p>
<h2 is-upgraded>Download Script</h2>
<p>Download the source code for this step <a href="https://github.com/datalabsolutions/AI-Labs/blob/main/snowflake-cortex-callcenter-lab/scripts/03-AI-LAB-EXTRACT_ANSWER.sql" target="_blank">here</a>.</p>
<h2 is-upgraded>Instructions</h2>
<p>This process allows you to extract named attributes from each call center transcript using targeted natural language prompts.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table to Store Caller Metadata</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CALLER 
(
    FILE_NAME VARCHAR,
    CALLER_NAME VARCHAR,
    CALL_DATE DATE,
    CALL_DURATION FLOAT,
    TRANSCRIPT VARCHAR
);
</code></pre>
<h2 is-upgraded>Step 2: Extract Caller Details with EXTRACT_ANSWER</h2>
<p>This step uses <code>EXTRACT_ANSWER()</code> to isolate structured values from each transcript using natural language prompts. The function returns an array of response objects. We access the first element <code>[0]</code> of the array, and retrieve the actual <code>answer</code> using the <code>:answer::string</code> projection.</p>
<ul>
<li><code>CALLER_NAME</code> is extracted by asking a direct question and accessing the top-ranked answer.</li>
<li><code>CALL_DATE</code> is converted to a valid date using <code>TRY_TO_DATE()</code> after cleaning whitespace.</li>
<li><code>CALL_DURATION</code> is parsed as a number using <code>TRY_TO_NUMBER()</code> to make it usable for aggregation or filtering.</li>
</ul>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CALLER  
SELECT
    FILE_NAME,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        TRANSCRIPT,
        &#39;What is the name of the caller?&#39;
    )[0]:answer::string AS CALLER_NAME,

    TRY_TO_DATE(REPLACE(SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        TRANSCRIPT,
        &#39;What is the Date of the call?&#39;
    )[0]:answer::string,&#39; &#39;,&#39;&#39;)) AS CALL_DATE,

    TRY_TO_NUMBER(REPLACE(SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        TRANSCRIPT,
        &#39;What is the call duration?&#39;
    )[0]:answer::string,&#39; &#39;,&#39;&#39;)) AS CALL_DURATION,

    TRANSCRIPT AS TRANSCRIPT
FROM 
    LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT;
</code></pre>
<h2 is-upgraded>Step 3: View Extracted Caller Details</h2>
<pre><code language="language-sql" class="language-sql">SELECT * FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CALLER;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="SUMMARIZE" duration="5">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>SUMMARIZE()</code> function to generate a concise, natural language summary of each call center transcript.</p>
<h2 is-upgraded>Download Script</h2>
<p>Download the source code for this step <a href="https://github.com/datalabsolutions/AI-Labs/blob/main/snowflake-cortex-callcenter-lab/scripts/04-AI-LAB-SUMMARIZE.sql" target="_blank">here</a>.</p>
<h2 is-upgraded>Instructions</h2>
<p>This allows you to extract the high-level meaning of each conversation, which is useful for reporting, escalation, or triage workflows.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table to Store Summaries</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_SUMMARY 
(
    FILE_NAME VARCHAR,
    TRANSCRIPT_SUMMARY VARCHAR,
    TRANSCRIPT VARCHAR
);
</code></pre>
<h2 is-upgraded>Step 2: Generate Summaries with SUMMARIZE</h2>
<p>This step uses the <code>SUMMARIZE()</code> function to produce a natural language summary of the full transcript. It processes the call dialogue and returns a concise description of what the call was about â€” including main themes, complaints, resolutions, or support actions mentioned.</p>
<p>The summary is especially useful for non-technical stakeholders, QA analysts, or automation workflows that depend on quick insights rather than full text review.</p>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_SUMMARY
SELECT
    FILE_NAME,
    SNOWFLAKE.CORTEX.SUMMARIZE(TRANSCRIPT) AS TRANSCRIPT_SUMMARY,
    TRANSCRIPT
FROM 
    LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT;
</code></pre>
<h2 is-upgraded>Step 3: View Summaries</h2>
<pre><code language="language-sql" class="language-sql">SELECT *
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_SUMMARY;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="SENTIMENT" duration="5">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>SENTIMENT()</code> function to detect the overall emotional tone of a transcript. This is especially helpful for assessing how a customer felt during a conversation.</p>
<h2 is-upgraded>Download Script</h2>
<p>Download the source code for this step <a href="https://github.com/datalabsolutions/AI-Labs/blob/main/snowflake-cortex-callcenter-lab/scripts/05-AI-LAB-SENTIMENT.sql" target="_blank">here</a>.</p>
<h2 is-upgraded>Instructions</h2>
<p>This function returns a numeric sentiment score ranging from -1 (very negative) to +1 (very positive), with 0 indicating neutral tone.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table to Store Sentiment Scores</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_SENTIMENT 
(
    FILE_NAME VARCHAR,
    OVERALL_SENTIMENT FLOAT,
    TRANSCRIPT VARCHAR
);
</code></pre>
<h2 is-upgraded>Step 2: Apply SENTIMENT Function to Transcripts</h2>
<p>Each transcript is analyzed to produce an overall sentiment score. This step runs <code>SENTIMENT()</code> against all rows in the transcript table and stores results for downstream insights.</p>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_SENTIMENT
SELECT
    FILE_NAME,
    SNOWFLAKE.CORTEX.SENTIMENT(TRANSCRIPT) AS OVERALL_SENTIMENT,
    TRANSCRIPT
FROM 
    LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT;
</code></pre>
<h2 is-upgraded>Step 3: View Sentiment Scores</h2>
<pre><code language="language-sql" class="language-sql">SELECT *
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_SENTIMENT;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="ENTITY_SENTIMENT" duration="6">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>ENTITY_SENTIMENT()</code> function to extract and evaluate how specific aspects â€” such as &#34;Tone of voice&#34;, &#34;Issue Resolved&#34;, and &#34;Follow up action&#34; â€” are discussed in each call transcript.</p>
<h2 is-upgraded>Download Script</h2>
<p>Download the source code for this step <a href="https://github.com/datalabsolutions/AI-Labs/blob/main/snowflake-cortex-callcenter-lab/scripts/06-AI-LAB-ENTITY_SENTIMENT.sql" target="_blank">here</a>.</p>
<h2 is-upgraded>Instructions</h2>
<p>This analysis focuses on targeted topics within transcripts and evaluates whether the sentiment around those entities is positive, neutral, or negative. The output is a JSON array that can be flattened to inspect each entity&#39;s sentiment.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table for Entity-Level Sentiment</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_ENTITY_SENTIMENT (
    FILE_NAME STRING,
    PRODUCT_ENTITY_SENTIMENT VARIANT,
    TRANSCRIPT VARIANT
);
</code></pre>
<h2 is-upgraded>Step 2: Extract Sentiment for Specific Entities</h2>
<p>This query applies the <code>ENTITY_SENTIMENT()</code> function to analyze sentiment for targeted entities within each transcript.</p>
<p>The <code>ARRAY_CONSTRUCT()</code> function is used to define the list of entity labels we want Cortex to evaluate. In this case, we specify:</p>
<ul>
<li><code>Tone of voice</code></li>
<li><code>Issue Resolved</code></li>
<li><code>Follow up action</code></li>
</ul>
<p>These are passed into the function as an array input. Cortex will search for each of these in the transcript and return structured sentiment scores (positive, neutral, or negative) with confidence values.</p>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_ENTITY_SENTIMENT
SELECT
    FILE_NAME,
    SNOWFLAKE.CORTEX.ENTITY_SENTIMENT(
        TRANSCRIPT,
        ARRAY_CONSTRUCT(&#39;Tone of voice&#39;, &#39;Issue Resolved&#39;, &#39;Follow up action&#39;)
    ) AS PRODUCT_ENTITY_SENTIMENT,
    TRANSCRIPT AS TRANSCRIPT
FROM
    LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT;
</code></pre>
<h2 is-upgraded>Step 3: View Flattened Sentiment by Entity</h2>
<p>Use the following query to transform the JSON result into a row-per-entity view using <code>FLATTEN()</code>:</p>
<pre><code language="language-sql" class="language-sql">SELECT
    FILE_NAME,
    flattened.value:entity::STRING AS ENTITY,
    flattened.value:sentiment::STRING AS SENTIMENT,
    flattened.value:confidence::FLOAT AS CONFIDENCE
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_ENTITY_SENTIMENT,
     LATERAL FLATTEN(INPUT =&gt; PRODUCT_ENTITY_SENTIMENT) AS flattened;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="CLASSIFY_TEXT" duration="5">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>CLASSIFY_TEXT()</code> function to categorize each call center transcript into predefined categories such as â€˜Report Incident&#39;, â€˜Complaint&#39;, or â€˜Follow up&#39;.</p>
<h2 is-upgraded>Download Script</h2>
<p>Download the source code for this step <a href="https://github.com/datalabsolutions/AI-Labs/blob/main/snowflake-cortex-callcenter-lab/scripts/07-AI-LAB-CLASSIFY_TEXT.sql" target="_blank">here</a>.</p>
<h2 is-upgraded>Instructions</h2>
<p>This classification helps group calls by intent or purpose. The function compares transcript content to label categories and returns the most appropriate label based on semantic similarity.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table for Transcript Classification</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CLASSIFICATION 
(
    FILE_NAME VARCHAR,
    CALL_CLASSIFICATION VARCHAR,
    TRANSCRIPT VARCHAR
);
</code></pre>
<h2 is-upgraded>Step 2: Classify Transcripts Using CLASSIFY_TEXT</h2>
<p>This step uses the <code>CLASSIFY_TEXT()</code> function with a predefined list of labels. It stores the most probable label into the classification table.</p>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CLASSIFICATION 
SELECT
    FILE_NAME,
    SNOWFLAKE.CORTEX.CLASSIFY_TEXT(
        TRANSCRIPT,
        ARRAY_CONSTRUCT(&#39;Report Incident&#39;, &#39;Complaint&#39;, &#39;Follow up&#39;)
    ):label::string AS CALL_CLASSIFICATION,
    TRANSCRIPT
FROM
    LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT;
</code></pre>
<h2 is-upgraded>Step 3: View Classified Results</h2>
<pre><code language="language-sql" class="language-sql">SELECT *
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CLASSIFICATION;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="COMPLETE" duration="7">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>COMPLETE()</code> function to extract detailed product references from transcripts and store the output as a structured JSON.</p>
<h2 is-upgraded>Instructions</h2>
<p>This function enables you to generate custom, structured outputs by engineering a prompt that guides the model to return specific fields. This is useful when extracting data that doesn&#39;t fit predefined functions.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table to Store Product Details</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_PRODUCTS AS
SELECT
    FILE_NAME,
    SNOWFLAKE.CORTEX.COMPLETE(
      &#39;gpt-4&#39;,
      &#39;Extract a JSON list of all products mentioned in this transcript. For each product, include the name, any feature discussed, and a short description of what the customer said about it.&#39;,
      TRANSCRIPT
    ) AS PRODUCT_DETAILS,
    TRANSCRIPT
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT;
</code></pre>
<h2 is-upgraded>Step 2: View Extracted Product Information</h2>
<pre><code language="language-sql" class="language-sql">SELECT *
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_PRODUCTS;
</code></pre>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/claat-public/native-shim.js"></script>
  <script src="https://storage.googleapis.com/claat-public/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/claat-public/prettify.js"></script>
  <script src="https://storage.googleapis.com/claat-public/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
