
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Snowflake Cortex AI for Call Center Transcript Analysis</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/claat-public/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14" ga4id=""></google-codelab-analytics>
  <google-codelab codelab-gaid="UA-XXXXXXXXX-X"
                  codelab-ga4id=""
                  id="snowflake-cortex-callcenter-lab"
                  title="Snowflake Cortex AI for Call Center Transcript Analysis"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Overview" duration="1">
        <p>This hands-on lab introduces participants to Snowflake Cortex AI&#39;s ability to extract valuable insights from unstructured documents using large language models. The lab uses examples of call center transcripts stored as PDFs. Participants will explore functions such as <a href="https://docs.snowflake.com/en/sql-reference/functions/parse_document" target="_blank"><code>PARSE_DOCUMENT</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/complete" target="_blank"><code>COMPLETE</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/translate" target="_blank"><code>TRANSLATE</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/sentiment" target="_blank"><code>SENTIMENT</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/entity_sentiment" target="_blank"><code>ENTITY_SENTIMENT</code></a>, <a href="https://docs.snowflake.com/en/sql-reference/functions/summarize" target="_blank"><code>SUMMARIZE</code></a>, and <a href="https://docs.snowflake.com/en/sql-reference/functions/extract_answer" target="_blank"><code>EXTRACT_ANSWER</code></a>. These tools empower users to parse, translate, analyze, and query unstructured customer support data to uncover sentiment, highlight issues, and summarize conversations at scale.</p>
<p>Whether you&#39;re a data engineer, business analyst, or AI enthusiast, this lab will help you understand how to turn raw documents into structured, actionable data using generative AI.</p>
<h2 class="checklist" is-upgraded>What you&#39;ll learn</h2>
<ul class="checklist">
<li>Upload and manage unstructured documents in Snowflake.</li>
<li>Extract and transform transcript text with <a href="https://docs.snowflake.com/en/sql-reference/functions/parse_document" target="_blank"><code>PARSE_DOCUMENT</code></a>.</li>
<li>Structure data using prompt engineering and the <a href="https://docs.snowflake.com/en/sql-reference/functions/complete" target="_blank"><code>COMPLETE</code></a> function.</li>
<li>Translate text with <a href="https://docs.snowflake.com/en/sql-reference/functions/translate" target="_blank"><code>TRANSLATE</code></a>.</li>
<li>Analyze sentiment using <a href="https://docs.snowflake.com/en/sql-reference/functions/sentiment" target="_blank"><code>SENTIMENT</code></a> and <a href="https://docs.snowflake.com/en/sql-reference/functions/entity_sentiment" target="_blank"><code>ENTITY_SENTIMENT</code></a>.</li>
<li>Summarize content with <a href="https://docs.snowflake.com/en/sql-reference/functions/summarize" target="_blank"><code>SUMMARIZE</code></a>.</li>
<li>Extract answers using <a href="https://docs.snowflake.com/en/sql-reference/functions/extract_answer" target="_blank"><code>EXTRACT_ANSWER</code></a>.</li>
</ul>
<h2 is-upgraded>Prerequisites</h2>
<p>To complete this lab, you will need:</p>
<ul>
<li>A <a href="https://trial.snowflake.com/?owner=SPN-PID-452710" target="_blank">Snowflake account</a> in a cloud region where <strong>Snowflake Cortex LLM functions</strong> are supported.</li>
<li>Basic familiarity with SQL and the Snowflake UI.</li>
</ul>
<p>ðŸ’¡ <strong>Tip:</strong> Not all Snowflake regions currently support Cortex LLM functions. Use the <a href="https://docs.snowflake.com/en/user-guide/snowflake-cortex-overview#llm-function-availability" target="_blank">LLM Function Availability</a> page to check which cloud regions are supported before creating your account.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Setup Environment" duration="10">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Prepare your Snowflake environment by creating a new database, warehouse, schemas, and internal stage, and upload call center transcript PDFs to that stage.</p>
<h2 is-upgraded>Step 1: Create Database Objects</h2>
<pre><code language="language-sql" class="language-sql">-- Step 1: Create Database
CREATE DATABASE IF NOT EXISTS LLM_CORTEX_DEMO_DB;

-- Step 2: Create Warehouse
CREATE OR REPLACE WAREHOUSE USER_STD_XSMALL_WH
WITH
    WAREHOUSE_SIZE = &#39;XSMALL&#39;
    WAREHOUSE_TYPE = &#39;STANDARD&#39;
    AUTO_SUSPEND = 60       -- suspend after 60 seconds of inactivity
    AUTO_RESUME = TRUE
    INITIALLY_SUSPENDED = TRUE;

-- Step 3: Create Schemas
CREATE SCHEMA IF NOT EXISTS LLM_CORTEX_DEMO_DB.RAW;
CREATE SCHEMA IF NOT EXISTS LLM_CORTEX_DEMO_DB.STAGE;

-- Step 4: Create Internal Stage for PDFs
CREATE OR REPLACE STAGE LLM_CORTEX_DEMO_DB.RAW.INT_STAGE_DOC_RAW
    DIRECTORY = ( ENABLE = true )
    ENCRYPTION = ( TYPE = &#39;SNOWFLAKE_SSE&#39; );
</code></pre>
<h2 is-upgraded>Step 2: Upload PDF Files to the Internal Stage</h2>
<p>Your internal stage <code>LLM_CORTEX_DEMO_DB.RAW.INT_STAGE_DOC_RAW</code> is already set up.</p>
<h3 is-upgraded>Using Snowsight:</h3>
<ol type="1">
<li>In Snowsight, go to <strong>Databases</strong>.</li>
<li>Click on <code>LLM_CORTEX_DEMO_DB</code> &gt; <code>RAW</code> &gt; <code>Stages</code>.</li>
<li>Select <code>INT_STAGE_DOC_RAW</code>.</li>
<li>Click the <strong>+ Files</strong> tab.</li>
<li>Click <strong>Upload</strong> and add one or more call center transcript PDFs.</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Parse PDF Documents" duration="7">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use the <code>PARSE_DOCUMENT()</code> function to extract the contents of uploaded PDF files from your internal stage and store them in a structured format as Markdown text.</p>
<h2 is-upgraded>Instructions</h2>
<p>You will now query the internal stage and use Snowflake Cortex to extract and parse the call center transcripts.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<p>Ensure you&#39;re working in the correct context before running the extraction steps:</p>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table for Parsed Results</h2>
<p>This table will store the extracted Markdown content for each uploaded file:</p>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT (
    FILE_NAME STRING,
    TRANSCRIPT VARIANT
);
</code></pre>
<h2 is-upgraded>Step 2: Extract PDF Content from Stage</h2>
<p>The query below uses <code>PARSE_DOCUMENT()</code> to extract and convert each PDF to Markdown format. Ensure you run this in the same warehouse and context created earlier:</p>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT
SELECT
    METADATA$FILENAME AS FILE_NAME,
    TRANSCRIPT(
        &#39;{&#34;format&#34;: &#34;markdown&#34;}&#39;,
        $1
    ) AS PARSED_CONTENT
FROM @LLM_CORTEX_DEMO_DB.RAW.INT_STAGE_DOC_RAW;
</code></pre>
<p>ðŸ’¡ <strong>Note:</strong> This approach stores both the filename and parsed content for downstream use. The Markdown format keeps the extracted structure readable for further processing.</p>
<h2 is-upgraded>Step 3: View Parsed Results</h2>
<p>Run the following query to view the extracted content from your PDF files:</p>
<pre><code language="language-sql" class="language-sql">SELECT
    FILE_NAME,
    PARSED_CONTENT
FROM LLM_CORTEX_DEMO_DB.STAGE.PARSED_TRANSCRIPTS;
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Identify Caller Using 
EXTRACT_ANSWER" duration="5">
        <h2 is-upgraded>Learning Outcome</h2>
<p>Use <code>EXTRACT_ANSWER()</code> to extract the name of the customer (caller) from each parsed call center transcript.</p>
<h2 is-upgraded>Set Snowflake Context</h2>
<p>Before proceeding, make sure your session is using the correct database, schema, and warehouse:</p>
<pre><code language="language-sql" class="language-sql">USE DATABASE LLM_CORTEX_DEMO_DB;
USE SCHEMA STAGE;
USE WAREHOUSE USER_STD_XSMALL_WH;
</code></pre>
<h2 is-upgraded>Step 1: Create a Table for Caller Names</h2>
<pre><code language="language-sql" class="language-sql">CREATE OR REPLACE TABLE LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CALLER (
    FILE_NAME STRING,
    CALLER_NAME STRING,
    TRANSCRIPT VARIANT
);
</code></pre>
<h2 is-upgraded>Step 2: Use <code>EXTRACT_ANSWER()</code> to Find the Caller&#39;s Name</h2>
<p>This query asks the model to extract the name of the customer involved in the conversation:</p>
<pre><code language="language-sql" class="language-sql">INSERT INTO LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CALLER
SELECT
    FILE_NAME,
    EXTRACT_ANSWER(
        &#39;gpt-4&#39;,
        &#39;What is the name of the customer speaking in this transcript? Only return the name.&#39;,
        PARSED_CONTENT:text
    ) AS CALLER_NAME,
    PARSED_CONTENT:text AS TRANSCRIPT
FROM LLM_CORTEX_DEMO_DB.STAGE.PARSED_TRANSCRIPTS;
</code></pre>
<h2 is-upgraded>Step 3: View Extracted Caller Names</h2>
<pre><code language="language-sql" class="language-sql">SELECT *
FROM LLM_CORTEX_DEMO_DB.STAGE.TRANSCRIPT_CALLER;
</code></pre>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/claat-public/native-shim.js"></script>
  <script src="https://storage.googleapis.com/claat-public/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/claat-public/prettify.js"></script>
  <script src="https://storage.googleapis.com/claat-public/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
